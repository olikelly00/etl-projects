{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top URL Per Country Per Date üìäüîé\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Run a SQL query against AWS Athena to retrieve data.\n",
    "2. Insert that data into a local PostgreSQL database.\n",
    "3. Read back the data from PostgreSQL and display it in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation üåêüêç\n",
    "\n",
    "- **boto3**: AWS SDK for Python, used to interact with AWS services like Athena.  \n",
    "- **psycopg2**: PostgreSQL database adapter for Python.  \n",
    "- **pandas**: Data analysis library for tabular data manipulation.  \n",
    "- **dotenv**: Loads environment variables from a local `.env` file.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "athena_client = boto3.client(\n",
    "    'athena',\n",
    "    region_name='eu-west-2',\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_KEY'))\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "SELECT server_request_country_code, DATE(datetime), event_url, COUNT(*) AS visit_count, \n",
    "RANK() OVER(PARTITION BY server_request_country_code ORDER BY COUNT(*) DESC) AS visit_count_rank\n",
    "FROM vod_clickstream\n",
    "WHERE DATE(datetime) BETWEEN CAST('2019-01-01' AS timestamp) AND CAST('2019-01-08' AS timestamp) \n",
    "GROUP BY server_request_country_code, DATE(datetime), event_url) ranked\n",
    "WHERE visit_count_rank = 1\n",
    "ORDER BY server_request_country_code, visit_count_rank;\n",
    "\"\"\"\n",
    "\n",
    "query_execution = athena_client.start_query_execution(\n",
    "    QueryString=sql_query,\n",
    "    QueryExecutionContext={\n",
    "        \"Database\": os.getenv('ATHENA_DATABASE_NAME')\n",
    "    },\n",
    "    ResultConfiguration={\n",
    "        \"OutputLocation\": os.getenv('S3_OUTPUT_LOCATION')\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation ‚òÅÔ∏è\n",
    "\n",
    "- **sql_query**: Defines the SQL statement to execute in Athena.  \n",
    "- **start_query_execution**: Submits the query to Athena.  \n",
    "- **QueryExecutionContext**: Tells Athena which database to use.  \n",
    "- **ResultConfiguration**: Tells Athena where to write query results on S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_status = \"QUEUED\"\n",
    "query_execution_id = query_execution[\"QueryExecutionId\"]\n",
    "\n",
    "while query_status in [\"QUEUED\", \"RUNNING\"]:\n",
    "    query_execution = athena_client.get_query_execution(\n",
    "        QueryExecutionId=query_execution_id\n",
    "    )\n",
    "    query_status = query_execution[\"QueryExecution\"][\"Status\"][\"State\"]\n",
    "    if query_status == \"FAILED\":\n",
    "        raise Exception(\"Athena query failed!\")\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation ‚åõ\n",
    "\n",
    "- **get_query_execution**: Checks the current status of the query using its **QueryExecutionId**.  \n",
    "- We loop until the query status is no longer `\"QUEUED\"` or `\"RUNNING\"`.  \n",
    "- If the query fails, we raise an exception.  \n",
    "- Otherwise, we sleep for 1 second between checks to avoid spamming the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = athena_client.get_query_results(\n",
    "    QueryExecutionId=query_execution_id\n",
    ")[\"ResultSet\"][\"Rows\"]\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(database=\"etl_bites\", user=\"olikelly\", password=\"i_am_a_password\", host=\"localhost\", port=\"5432\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS top_url_per_country_per_date;\n",
    "    CREATE TABLE top_url_per_country_per_date (\n",
    "        date VARCHAR,\n",
    "        country_code VARCHAR,\n",
    "        url VARCHAR,\n",
    "        visit_count INTEGER,\n",
    "        rank INTEGER\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation üêò\n",
    "\n",
    "- **get_query_results**: Fetches the actual data returned by the SQL query.  \n",
    "- The result is a dictionary that includes `[\"ResultSet\"][\"Rows\"]`, which is a list where the first row usually contains column headers, and subsequent rows contain actual data.  \n",
    "- **psycopg2.connect**: Creates a connection to your local PostgreSQL.  \n",
    "- We **DROP** the table if it exists, then **CREATE** it anew.  \n",
    "- This ensures we‚Äôre starting with a blank table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row: {'Data': [{'VarCharValue': ''}, {'VarCharValue': '2019-01-06'}, {'VarCharValue': 'https://www.netflix.com/'}, {'VarCharValue': '44'}, {'VarCharValue': '1'}]}\n"
     ]
    }
   ],
   "source": [
    "for row in results[1:]:\n",
    "    if row[\"Data\"][0]['VarCharValue'] == '' or row[\"Data\"][1]['VarCharValue'] == '' or row[\"Data\"][2]['VarCharValue'] == '' or row[\"Data\"][3]['VarCharValue'] == '' or row[\"Data\"][4]['VarCharValue'] == '':\n",
    "        print(f\"Skipping row: {row}\")\n",
    "        continue\n",
    "\n",
    "    date = row[\"Data\"][0][\"VarCharValue\"]\n",
    "    country_code = row[\"Data\"][1][\"VarCharValue\"]\n",
    "    url = row[\"Data\"][2][\"VarCharValue\"]\n",
    "    visit_count = int(row[\"Data\"][3][\"VarCharValue\"])\n",
    "    visit_count_rank = int(row[\"Data\"][4][\"VarCharValue\"])\n",
    "\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO top_url_per_country_per_date (date, url, country_code, visit_count, rank)\n",
    "        VALUES (%s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        cursor.execute(insert_query, (country_code, url, date, visit_count, visit_count_rank))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred inserting into analytical DB: %s\"% e)\n",
    "        conn.rollback()  # Rollback the transaction if there's an error\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation üíæ\n",
    "\n",
    "- We **skip** the first row (the header).\n",
    "- For each row, we access `[\"Data\"]`, which is a list of dicts like `{\"VarCharValue\": \"some_value\"}`.\n",
    "- We retrieve each field, convert numeric fields to `int`, and insert them into the table.\n",
    "- If any error occurs, we rollback the transaction for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country_code</th>\n",
       "      <th>url</th>\n",
       "      <th>visit_count</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>AD</td>\n",
       "      <td>https://www.netflix.com/ad/</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>AD</td>\n",
       "      <td>https://www.netflix.com/search?q=black%20mirr</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>AE</td>\n",
       "      <td>https://www.netflix.com/browse</td>\n",
       "      <td>598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>AF</td>\n",
       "      <td>https://www.netflix.com/browse</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>AG</td>\n",
       "      <td>https://www.netflix.com/browse</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>YT</td>\n",
       "      <td>https://www.netflix.com/browse</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>ZA</td>\n",
       "      <td>https://www.netflix.com/browse</td>\n",
       "      <td>1288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>ZM</td>\n",
       "      <td>https://www.netflix.com/browse</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>ZM</td>\n",
       "      <td>https://www.netflix.com/browse</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>ZW</td>\n",
       "      <td>https://www.netflix.com/browse</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date country_code                                            url  \\\n",
       "0    2019-01-05           AD                    https://www.netflix.com/ad/   \n",
       "1    2019-01-06           AD  https://www.netflix.com/search?q=black%20mirr   \n",
       "2    2019-01-05           AE                 https://www.netflix.com/browse   \n",
       "3    2019-01-04           AF                 https://www.netflix.com/browse   \n",
       "4    2019-01-02           AG                 https://www.netflix.com/browse   \n",
       "..          ...          ...                                            ...   \n",
       "279  2019-01-02           YT                 https://www.netflix.com/browse   \n",
       "280  2019-01-05           ZA                 https://www.netflix.com/browse   \n",
       "281  2019-01-08           ZM                 https://www.netflix.com/browse   \n",
       "282  2019-01-04           ZM                 https://www.netflix.com/browse   \n",
       "283  2019-01-02           ZW                 https://www.netflix.com/browse   \n",
       "\n",
       "     visit_count  rank  \n",
       "0              3     1  \n",
       "1              3     1  \n",
       "2            598     1  \n",
       "3             12     1  \n",
       "4             10     1  \n",
       "..           ...   ...  \n",
       "279           22     1  \n",
       "280         1288     1  \n",
       "281           28     1  \n",
       "282           28     1  \n",
       "283           47     1  \n",
       "\n",
       "[284 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn_string = \"dbname=etl_bites user=olikelly password=i_am_a_password host=localhost port='5432'\"\n",
    "query = 'SELECT * FROM top_url_per_country_per_date;'\n",
    "\n",
    "def read_data_from_postgresql(conn_string, query):\n",
    "    with psycopg2.connect(conn_string) as conn:\n",
    "        with conn.cursor() as cur:     \n",
    "            cur.execute(query)\n",
    "            data = cur.fetchall()\n",
    "            colnames = cur.description\n",
    "            return colnames, data\n",
    "\n",
    "result = read_data_from_postgresql(conn_string, query)\n",
    "columns = [column[0] for column in result[0]]\n",
    "data = result[1]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation üîé\n",
    "\n",
    "- We run `SELECT *` to ensure our data was inserted successfully.\n",
    "- `cursor.fetchall()` gives us a list of tuples.\n",
    "- We build a DataFrame using the column names from `cursor.description`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-bites",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
